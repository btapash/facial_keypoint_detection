{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facial_keypoints.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1n67Zcmb4xJ",
        "colab_type": "text"
      },
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHnVjZVPdGu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras.layers import Dense, Activation, MaxPool2D, ZeroPadding2D, Conv2D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.advanced_activations import LeakyReLU\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH3GXG5KcBrd",
        "colab_type": "text"
      },
      "source": [
        "**Loading Training** **datasets** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNJ3pS-2kLRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/facial_keypoint/training.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxoxE-mclJGj",
        "colab_type": "code",
        "outputId": "ca52497d-708a-4045-f561-94f73267905a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>left_eye_center_x</th>\n",
              "      <th>left_eye_center_y</th>\n",
              "      <th>right_eye_center_x</th>\n",
              "      <th>right_eye_center_y</th>\n",
              "      <th>left_eye_inner_corner_x</th>\n",
              "      <th>left_eye_inner_corner_y</th>\n",
              "      <th>left_eye_outer_corner_x</th>\n",
              "      <th>left_eye_outer_corner_y</th>\n",
              "      <th>right_eye_inner_corner_x</th>\n",
              "      <th>right_eye_inner_corner_y</th>\n",
              "      <th>right_eye_outer_corner_x</th>\n",
              "      <th>right_eye_outer_corner_y</th>\n",
              "      <th>left_eyebrow_inner_end_x</th>\n",
              "      <th>left_eyebrow_inner_end_y</th>\n",
              "      <th>left_eyebrow_outer_end_x</th>\n",
              "      <th>left_eyebrow_outer_end_y</th>\n",
              "      <th>right_eyebrow_inner_end_x</th>\n",
              "      <th>right_eyebrow_inner_end_y</th>\n",
              "      <th>right_eyebrow_outer_end_x</th>\n",
              "      <th>right_eyebrow_outer_end_y</th>\n",
              "      <th>nose_tip_x</th>\n",
              "      <th>nose_tip_y</th>\n",
              "      <th>mouth_left_corner_x</th>\n",
              "      <th>mouth_left_corner_y</th>\n",
              "      <th>mouth_right_corner_x</th>\n",
              "      <th>mouth_right_corner_y</th>\n",
              "      <th>mouth_center_top_lip_x</th>\n",
              "      <th>mouth_center_top_lip_y</th>\n",
              "      <th>mouth_center_bottom_lip_x</th>\n",
              "      <th>mouth_center_bottom_lip_y</th>\n",
              "      <th>Image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>66.033564</td>\n",
              "      <td>39.002274</td>\n",
              "      <td>30.227008</td>\n",
              "      <td>36.421678</td>\n",
              "      <td>59.582075</td>\n",
              "      <td>39.647423</td>\n",
              "      <td>73.130346</td>\n",
              "      <td>39.969997</td>\n",
              "      <td>36.356571</td>\n",
              "      <td>37.389402</td>\n",
              "      <td>23.452872</td>\n",
              "      <td>37.389402</td>\n",
              "      <td>56.953263</td>\n",
              "      <td>29.033648</td>\n",
              "      <td>80.227128</td>\n",
              "      <td>32.228138</td>\n",
              "      <td>40.227609</td>\n",
              "      <td>29.002322</td>\n",
              "      <td>16.356379</td>\n",
              "      <td>29.647471</td>\n",
              "      <td>44.420571</td>\n",
              "      <td>57.066803</td>\n",
              "      <td>61.195308</td>\n",
              "      <td>79.970165</td>\n",
              "      <td>28.614496</td>\n",
              "      <td>77.388992</td>\n",
              "      <td>43.312602</td>\n",
              "      <td>72.935459</td>\n",
              "      <td>43.130707</td>\n",
              "      <td>84.485774</td>\n",
              "      <td>238 236 237 238 240 240 239 241 241 243 240 23...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>64.332936</td>\n",
              "      <td>34.970077</td>\n",
              "      <td>29.949277</td>\n",
              "      <td>33.448715</td>\n",
              "      <td>58.856170</td>\n",
              "      <td>35.274349</td>\n",
              "      <td>70.722723</td>\n",
              "      <td>36.187166</td>\n",
              "      <td>36.034723</td>\n",
              "      <td>34.361532</td>\n",
              "      <td>24.472511</td>\n",
              "      <td>33.144443</td>\n",
              "      <td>53.987404</td>\n",
              "      <td>28.275949</td>\n",
              "      <td>78.634213</td>\n",
              "      <td>30.405923</td>\n",
              "      <td>42.728851</td>\n",
              "      <td>26.146043</td>\n",
              "      <td>16.865362</td>\n",
              "      <td>27.058860</td>\n",
              "      <td>48.206298</td>\n",
              "      <td>55.660936</td>\n",
              "      <td>56.421447</td>\n",
              "      <td>76.352000</td>\n",
              "      <td>35.122383</td>\n",
              "      <td>76.047660</td>\n",
              "      <td>46.684596</td>\n",
              "      <td>70.266553</td>\n",
              "      <td>45.467915</td>\n",
              "      <td>85.480170</td>\n",
              "      <td>219 215 204 196 204 211 212 200 180 168 178 19...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.057053</td>\n",
              "      <td>34.909642</td>\n",
              "      <td>30.903789</td>\n",
              "      <td>34.909642</td>\n",
              "      <td>59.412000</td>\n",
              "      <td>36.320968</td>\n",
              "      <td>70.984421</td>\n",
              "      <td>36.320968</td>\n",
              "      <td>37.678105</td>\n",
              "      <td>36.320968</td>\n",
              "      <td>24.976421</td>\n",
              "      <td>36.603221</td>\n",
              "      <td>55.742526</td>\n",
              "      <td>27.570947</td>\n",
              "      <td>78.887368</td>\n",
              "      <td>32.651621</td>\n",
              "      <td>42.193895</td>\n",
              "      <td>28.135453</td>\n",
              "      <td>16.791158</td>\n",
              "      <td>32.087116</td>\n",
              "      <td>47.557263</td>\n",
              "      <td>53.538947</td>\n",
              "      <td>60.822947</td>\n",
              "      <td>73.014316</td>\n",
              "      <td>33.726316</td>\n",
              "      <td>72.732000</td>\n",
              "      <td>47.274947</td>\n",
              "      <td>70.191789</td>\n",
              "      <td>47.274947</td>\n",
              "      <td>78.659368</td>\n",
              "      <td>144 142 159 180 188 188 184 180 167 132 84 59 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65.225739</td>\n",
              "      <td>37.261774</td>\n",
              "      <td>32.023096</td>\n",
              "      <td>37.261774</td>\n",
              "      <td>60.003339</td>\n",
              "      <td>39.127179</td>\n",
              "      <td>72.314713</td>\n",
              "      <td>38.380967</td>\n",
              "      <td>37.618643</td>\n",
              "      <td>38.754115</td>\n",
              "      <td>25.307270</td>\n",
              "      <td>38.007903</td>\n",
              "      <td>56.433809</td>\n",
              "      <td>30.929864</td>\n",
              "      <td>77.910261</td>\n",
              "      <td>31.665725</td>\n",
              "      <td>41.671513</td>\n",
              "      <td>31.049990</td>\n",
              "      <td>20.458017</td>\n",
              "      <td>29.909343</td>\n",
              "      <td>51.885078</td>\n",
              "      <td>54.166539</td>\n",
              "      <td>65.598887</td>\n",
              "      <td>72.703722</td>\n",
              "      <td>37.245496</td>\n",
              "      <td>74.195478</td>\n",
              "      <td>50.303165</td>\n",
              "      <td>70.091687</td>\n",
              "      <td>51.561183</td>\n",
              "      <td>78.268383</td>\n",
              "      <td>193 192 193 194 194 194 193 192 168 111 50 12 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>66.725301</td>\n",
              "      <td>39.621261</td>\n",
              "      <td>32.244810</td>\n",
              "      <td>38.042032</td>\n",
              "      <td>58.565890</td>\n",
              "      <td>39.621261</td>\n",
              "      <td>72.515926</td>\n",
              "      <td>39.884466</td>\n",
              "      <td>36.982380</td>\n",
              "      <td>39.094852</td>\n",
              "      <td>22.506110</td>\n",
              "      <td>38.305237</td>\n",
              "      <td>57.249571</td>\n",
              "      <td>30.672177</td>\n",
              "      <td>77.762945</td>\n",
              "      <td>31.737247</td>\n",
              "      <td>38.035436</td>\n",
              "      <td>30.935382</td>\n",
              "      <td>15.925870</td>\n",
              "      <td>30.672177</td>\n",
              "      <td>43.299534</td>\n",
              "      <td>64.889521</td>\n",
              "      <td>60.671411</td>\n",
              "      <td>77.523239</td>\n",
              "      <td>31.191755</td>\n",
              "      <td>76.997301</td>\n",
              "      <td>44.962748</td>\n",
              "      <td>73.707387</td>\n",
              "      <td>44.227141</td>\n",
              "      <td>86.871166</td>\n",
              "      <td>147 148 160 196 215 214 216 217 219 220 206 18...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   left_eye_center_x  ...                                              Image\n",
              "0          66.033564  ...  238 236 237 238 240 240 239 241 241 243 240 23...\n",
              "1          64.332936  ...  219 215 204 196 204 211 212 200 180 168 178 19...\n",
              "2          65.057053  ...  144 142 159 180 188 188 184 180 167 132 84 59 ...\n",
              "3          65.225739  ...  193 192 193 194 194 194 193 192 168 111 50 12 ...\n",
              "4          66.725301  ...  147 148 160 196 215 214 216 217 219 220 206 18...\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2iK0yhnladN",
        "colab_type": "code",
        "outputId": "8cd8caa5-f694-4eda-c7f5-0d845ab76db2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "print(train.isnull().sum(axis=0))\n",
        "train.isnull().any().value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "left_eye_center_x              10\n",
            "left_eye_center_y              10\n",
            "right_eye_center_x             13\n",
            "right_eye_center_y             13\n",
            "left_eye_inner_corner_x      4778\n",
            "left_eye_inner_corner_y      4778\n",
            "left_eye_outer_corner_x      4782\n",
            "left_eye_outer_corner_y      4782\n",
            "right_eye_inner_corner_x     4781\n",
            "right_eye_inner_corner_y     4781\n",
            "right_eye_outer_corner_x     4781\n",
            "right_eye_outer_corner_y     4781\n",
            "left_eyebrow_inner_end_x     4779\n",
            "left_eyebrow_inner_end_y     4779\n",
            "left_eyebrow_outer_end_x     4824\n",
            "left_eyebrow_outer_end_y     4824\n",
            "right_eyebrow_inner_end_x    4779\n",
            "right_eyebrow_inner_end_y    4779\n",
            "right_eyebrow_outer_end_x    4813\n",
            "right_eyebrow_outer_end_y    4813\n",
            "nose_tip_x                      0\n",
            "nose_tip_y                      0\n",
            "mouth_left_corner_x          4780\n",
            "mouth_left_corner_y          4780\n",
            "mouth_right_corner_x         4779\n",
            "mouth_right_corner_y         4779\n",
            "mouth_center_top_lip_x       4774\n",
            "mouth_center_top_lip_y       4774\n",
            "mouth_center_bottom_lip_x      33\n",
            "mouth_center_bottom_lip_y      33\n",
            "Image                           0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     28\n",
              "False     3\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u1w0gSHs4SK",
        "colab_type": "code",
        "outputId": "0ad04506-24a7-4bc0-afec-a722764c4f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7049, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdz9w95Tq3-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.fillna(method='ffill', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuRxZ3drsHW-",
        "colab_type": "code",
        "outputId": "d0851ea9-90c1-448c-eced-a655940672ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "train.isnull().sum(axis=0)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "left_eye_center_x            0\n",
              "left_eye_center_y            0\n",
              "right_eye_center_x           0\n",
              "right_eye_center_y           0\n",
              "left_eye_inner_corner_x      0\n",
              "left_eye_inner_corner_y      0\n",
              "left_eye_outer_corner_x      0\n",
              "left_eye_outer_corner_y      0\n",
              "right_eye_inner_corner_x     0\n",
              "right_eye_inner_corner_y     0\n",
              "right_eye_outer_corner_x     0\n",
              "right_eye_outer_corner_y     0\n",
              "left_eyebrow_inner_end_x     0\n",
              "left_eyebrow_inner_end_y     0\n",
              "left_eyebrow_outer_end_x     0\n",
              "left_eyebrow_outer_end_y     0\n",
              "right_eyebrow_inner_end_x    0\n",
              "right_eyebrow_inner_end_y    0\n",
              "right_eyebrow_outer_end_x    0\n",
              "right_eyebrow_outer_end_y    0\n",
              "nose_tip_x                   0\n",
              "nose_tip_y                   0\n",
              "mouth_left_corner_x          0\n",
              "mouth_left_corner_y          0\n",
              "mouth_right_corner_x         0\n",
              "mouth_right_corner_y         0\n",
              "mouth_center_top_lip_x       0\n",
              "mouth_center_top_lip_y       0\n",
              "mouth_center_bottom_lip_x    0\n",
              "mouth_center_bottom_lip_y    0\n",
              "Image                        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OaAIVVuhUTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['Image']=train['Image'].apply(lambda x: np.fromstring(x, sep=' ') )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgqQq5Gulzwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "1006c064-74f8-4db3-9b34-6257a065e9ce"
      },
      "source": [
        "train['Image']\n",
        "#check accuracy after normalization"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [238.0, 236.0, 237.0, 238.0, 240.0, 240.0, 239...\n",
              "1       [219.0, 215.0, 204.0, 196.0, 204.0, 211.0, 212...\n",
              "2       [144.0, 142.0, 159.0, 180.0, 188.0, 188.0, 184...\n",
              "3       [193.0, 192.0, 193.0, 194.0, 194.0, 194.0, 193...\n",
              "4       [147.0, 148.0, 160.0, 196.0, 215.0, 214.0, 216...\n",
              "                              ...                        \n",
              "7044    [71.0, 74.0, 85.0, 105.0, 116.0, 128.0, 139.0,...\n",
              "7045    [60.0, 60.0, 62.0, 57.0, 55.0, 51.0, 49.0, 48....\n",
              "7046    [74.0, 74.0, 74.0, 78.0, 79.0, 79.0, 79.0, 81....\n",
              "7047    [254.0, 254.0, 254.0, 254.0, 254.0, 238.0, 193...\n",
              "7048    [53.0, 62.0, 67.0, 76.0, 86.0, 91.0, 97.0, 105...\n",
              "Name: Image, Length: 7049, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7ltqlvBm674",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img=train['Image']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPAZzPVL1jLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_list=np.vstack(img.values)\n",
        "img_list=img_list.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njvAHwFS7rBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=img_list.reshape(-1,96,96,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA-xQRIL0XmS",
        "colab_type": "code",
        "outputId": "39fc2d52-d92e-4abd-e745-9c7480c33bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[238.],\n",
              "         [236.],\n",
              "         [237.],\n",
              "         ...,\n",
              "         [250.],\n",
              "         [250.],\n",
              "         [250.]],\n",
              "\n",
              "        [[235.],\n",
              "         [238.],\n",
              "         [236.],\n",
              "         ...,\n",
              "         [249.],\n",
              "         [250.],\n",
              "         [251.]],\n",
              "\n",
              "        [[237.],\n",
              "         [236.],\n",
              "         [237.],\n",
              "         ...,\n",
              "         [251.],\n",
              "         [251.],\n",
              "         [250.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[186.],\n",
              "         [183.],\n",
              "         [181.],\n",
              "         ...,\n",
              "         [ 52.],\n",
              "         [ 57.],\n",
              "         [ 60.]],\n",
              "\n",
              "        [[189.],\n",
              "         [188.],\n",
              "         [207.],\n",
              "         ...,\n",
              "         [ 61.],\n",
              "         [ 69.],\n",
              "         [ 78.]],\n",
              "\n",
              "        [[191.],\n",
              "         [184.],\n",
              "         [184.],\n",
              "         ...,\n",
              "         [ 70.],\n",
              "         [ 75.],\n",
              "         [ 90.]]],\n",
              "\n",
              "\n",
              "       [[[219.],\n",
              "         [215.],\n",
              "         [204.],\n",
              "         ...,\n",
              "         [ 92.],\n",
              "         [ 88.],\n",
              "         [ 84.]],\n",
              "\n",
              "        [[222.],\n",
              "         [219.],\n",
              "         [220.],\n",
              "         ...,\n",
              "         [ 92.],\n",
              "         [ 88.],\n",
              "         [ 86.]],\n",
              "\n",
              "        [[231.],\n",
              "         [224.],\n",
              "         [212.],\n",
              "         ...,\n",
              "         [ 77.],\n",
              "         [ 80.],\n",
              "         [ 84.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[  1.],\n",
              "         [  1.],\n",
              "         [  1.],\n",
              "         ...,\n",
              "         [  1.],\n",
              "         [  1.],\n",
              "         [  1.]],\n",
              "\n",
              "        [[  1.],\n",
              "         [  1.],\n",
              "         [  1.],\n",
              "         ...,\n",
              "         [  1.],\n",
              "         [  1.],\n",
              "         [  1.]],\n",
              "\n",
              "        [[  1.],\n",
              "         [  1.],\n",
              "         [  1.],\n",
              "         ...,\n",
              "         [  1.],\n",
              "         [  1.],\n",
              "         [  1.]]],\n",
              "\n",
              "\n",
              "       [[[144.],\n",
              "         [142.],\n",
              "         [159.],\n",
              "         ...,\n",
              "         [208.],\n",
              "         [207.],\n",
              "         [207.]],\n",
              "\n",
              "        [[143.],\n",
              "         [142.],\n",
              "         [161.],\n",
              "         ...,\n",
              "         [208.],\n",
              "         [208.],\n",
              "         [207.]],\n",
              "\n",
              "        [[143.],\n",
              "         [140.],\n",
              "         [160.],\n",
              "         ...,\n",
              "         [209.],\n",
              "         [209.],\n",
              "         [207.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 66.],\n",
              "         [ 70.],\n",
              "         [ 69.],\n",
              "         ...,\n",
              "         [ 81.],\n",
              "         [134.],\n",
              "         [194.]],\n",
              "\n",
              "        [[ 65.],\n",
              "         [ 69.],\n",
              "         [ 71.],\n",
              "         ...,\n",
              "         [ 75.],\n",
              "         [ 83.],\n",
              "         [109.]],\n",
              "\n",
              "        [[ 65.],\n",
              "         [ 68.],\n",
              "         [ 70.],\n",
              "         ...,\n",
              "         [ 78.],\n",
              "         [ 78.],\n",
              "         [ 77.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 74.],\n",
              "         [ 74.],\n",
              "         [ 74.],\n",
              "         ...,\n",
              "         [ 68.],\n",
              "         [ 60.],\n",
              "         [ 64.]],\n",
              "\n",
              "        [[ 74.],\n",
              "         [ 74.],\n",
              "         [ 74.],\n",
              "         ...,\n",
              "         [ 67.],\n",
              "         [ 63.],\n",
              "         [ 62.]],\n",
              "\n",
              "        [[ 74.],\n",
              "         [ 74.],\n",
              "         [ 74.],\n",
              "         ...,\n",
              "         [ 69.],\n",
              "         [ 66.],\n",
              "         [ 60.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 24.],\n",
              "         [ 24.],\n",
              "         [ 24.],\n",
              "         ...,\n",
              "         [ 20.],\n",
              "         [ 20.],\n",
              "         [ 20.]],\n",
              "\n",
              "        [[ 25.],\n",
              "         [ 25.],\n",
              "         [ 25.],\n",
              "         ...,\n",
              "         [ 20.],\n",
              "         [ 20.],\n",
              "         [ 20.]],\n",
              "\n",
              "        [[ 25.],\n",
              "         [ 25.],\n",
              "         [ 25.],\n",
              "         ...,\n",
              "         [ 20.],\n",
              "         [ 20.],\n",
              "         [ 20.]]],\n",
              "\n",
              "\n",
              "       [[[254.],\n",
              "         [254.],\n",
              "         [254.],\n",
              "         ...,\n",
              "         [250.],\n",
              "         [253.],\n",
              "         [254.]],\n",
              "\n",
              "        [[254.],\n",
              "         [254.],\n",
              "         [254.],\n",
              "         ...,\n",
              "         [245.],\n",
              "         [253.],\n",
              "         [254.]],\n",
              "\n",
              "        [[254.],\n",
              "         [254.],\n",
              "         [254.],\n",
              "         ...,\n",
              "         [248.],\n",
              "         [253.],\n",
              "         [254.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[254.],\n",
              "         [254.],\n",
              "         [254.],\n",
              "         ...,\n",
              "         [254.],\n",
              "         [254.],\n",
              "         [254.]],\n",
              "\n",
              "        [[254.],\n",
              "         [254.],\n",
              "         [254.],\n",
              "         ...,\n",
              "         [254.],\n",
              "         [254.],\n",
              "         [254.]],\n",
              "\n",
              "        [[254.],\n",
              "         [254.],\n",
              "         [254.],\n",
              "         ...,\n",
              "         [254.],\n",
              "         [254.],\n",
              "         [254.]]],\n",
              "\n",
              "\n",
              "       [[[ 53.],\n",
              "         [ 62.],\n",
              "         [ 67.],\n",
              "         ...,\n",
              "         [120.],\n",
              "         [117.],\n",
              "         [ 97.]],\n",
              "\n",
              "        [[ 53.],\n",
              "         [ 64.],\n",
              "         [ 70.],\n",
              "         ...,\n",
              "         [114.],\n",
              "         [113.],\n",
              "         [ 96.]],\n",
              "\n",
              "        [[ 60.],\n",
              "         [ 70.],\n",
              "         [ 77.],\n",
              "         ...,\n",
              "         [106.],\n",
              "         [108.],\n",
              "         [ 94.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 41.],\n",
              "         [ 56.],\n",
              "         [ 77.],\n",
              "         ...,\n",
              "         [159.],\n",
              "         [155.],\n",
              "         [153.]],\n",
              "\n",
              "        [[ 41.],\n",
              "         [ 48.],\n",
              "         [ 67.],\n",
              "         ...,\n",
              "         [159.],\n",
              "         [157.],\n",
              "         [157.]],\n",
              "\n",
              "        [[ 46.],\n",
              "         [ 44.],\n",
              "         [ 56.],\n",
              "         ...,\n",
              "         [158.],\n",
              "         [158.],\n",
              "         [159.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY1TGYG9zscI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train=train[train.columns[:-1]].values\n",
        "Y_train=Y_train.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2c98NEJ0WO4",
        "colab_type": "text"
      },
      "source": [
        "CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBHFg7FW4fA3",
        "colab_type": "code",
        "outputId": "803d5854-e321-4a60-87fc-b1ba935bf60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3,3), padding='same', use_bias=False, input_shape=(96,96,1)))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(96, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(96, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3,3),padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, (3,3),padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3,3),padding='same',use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(256, (3,3),padding='same',use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(512, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(512, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(30))\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 96, 96, 32)        288       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 96, 96, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 96, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 96, 96, 32)        9216      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 96, 96, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 96, 96, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 48, 48, 64)        18432     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 48, 48, 64)        36864     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 24, 24, 96)        55296     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 24, 24, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 24, 24, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 24, 24, 96)        82944     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 24, 24, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 24, 24, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 12, 12, 128)       110592    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 12, 12, 128)       147456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 6, 6, 256)         294912    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 6, 6, 256)         589824    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 3, 3, 512)         1179648   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 3, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 3, 3, 512)         2359296   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 3, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               2359808   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 30)                15390     \n",
            "=================================================================\n",
            "Total params: 7,268,670\n",
            "Trainable params: 7,264,318\n",
            "Non-trainable params: 4,352\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peQi6Eoo4qEs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "96792c2b-fd32-4452-e1c3-5642464c5a07"
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mae'])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdEC8jma41VN",
        "colab_type": "code",
        "outputId": "21e24254-a0cc-4005-9b7a-d7e9adc40cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train,Y_train,epochs = 50,batch_size = 250,validation_split = 0.25)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5286 samples, validate on 1763 samples\n",
            "Epoch 1/50\n",
            "5286/5286 [==============================] - 9s 2ms/step - loss: 2.9027 - mean_absolute_error: 1.2699 - val_loss: 3.5014 - val_mean_absolute_error: 1.3637\n",
            "Epoch 2/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.9596 - mean_absolute_error: 1.2892 - val_loss: 1.5252 - val_mean_absolute_error: 0.5468\n",
            "Epoch 3/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5727 - mean_absolute_error: 1.1931 - val_loss: 2.0022 - val_mean_absolute_error: 0.9424\n",
            "Epoch 4/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.8916 - mean_absolute_error: 1.2672 - val_loss: 4.9420 - val_mean_absolute_error: 1.8267\n",
            "Epoch 5/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 3.5840 - mean_absolute_error: 1.4321 - val_loss: 3.2241 - val_mean_absolute_error: 1.1566\n",
            "Epoch 6/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.7571 - mean_absolute_error: 1.2376 - val_loss: 3.0619 - val_mean_absolute_error: 1.3123\n",
            "Epoch 7/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.7770 - mean_absolute_error: 1.2377 - val_loss: 1.7086 - val_mean_absolute_error: 0.6994\n",
            "Epoch 8/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.8056 - mean_absolute_error: 1.2489 - val_loss: 2.9636 - val_mean_absolute_error: 1.0978\n",
            "Epoch 9/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5737 - mean_absolute_error: 1.1903 - val_loss: 2.2798 - val_mean_absolute_error: 0.7099\n",
            "Epoch 10/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.9059 - mean_absolute_error: 1.2727 - val_loss: 2.2550 - val_mean_absolute_error: 0.7565\n",
            "Epoch 11/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5935 - mean_absolute_error: 1.1920 - val_loss: 1.9155 - val_mean_absolute_error: 0.7386\n",
            "Epoch 12/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5953 - mean_absolute_error: 1.1951 - val_loss: 1.8236 - val_mean_absolute_error: 0.6545\n",
            "Epoch 13/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5767 - mean_absolute_error: 1.1982 - val_loss: 1.8017 - val_mean_absolute_error: 0.6916\n",
            "Epoch 14/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.6004 - mean_absolute_error: 1.1978 - val_loss: 2.1120 - val_mean_absolute_error: 0.8338\n",
            "Epoch 15/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.9049 - mean_absolute_error: 1.2753 - val_loss: 2.0142 - val_mean_absolute_error: 0.7152\n",
            "Epoch 16/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5491 - mean_absolute_error: 1.1883 - val_loss: 2.1922 - val_mean_absolute_error: 0.8436\n",
            "Epoch 17/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.6749 - mean_absolute_error: 1.2211 - val_loss: 2.0760 - val_mean_absolute_error: 0.8569\n",
            "Epoch 18/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.6226 - mean_absolute_error: 1.2076 - val_loss: 1.7890 - val_mean_absolute_error: 0.6427\n",
            "Epoch 19/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.8027 - mean_absolute_error: 1.2553 - val_loss: 2.6597 - val_mean_absolute_error: 1.0663\n",
            "Epoch 20/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.8417 - mean_absolute_error: 1.2625 - val_loss: 2.8665 - val_mean_absolute_error: 1.1416\n",
            "Epoch 21/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.9778 - mean_absolute_error: 1.2886 - val_loss: 1.6544 - val_mean_absolute_error: 0.6026\n",
            "Epoch 22/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5740 - mean_absolute_error: 1.1879 - val_loss: 2.5319 - val_mean_absolute_error: 0.8202\n",
            "Epoch 23/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.8209 - mean_absolute_error: 1.2542 - val_loss: 1.8517 - val_mean_absolute_error: 0.7175\n",
            "Epoch 24/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5867 - mean_absolute_error: 1.1954 - val_loss: 1.8781 - val_mean_absolute_error: 0.6823\n",
            "Epoch 25/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5840 - mean_absolute_error: 1.1929 - val_loss: 2.6912 - val_mean_absolute_error: 1.0161\n",
            "Epoch 26/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.7430 - mean_absolute_error: 1.2423 - val_loss: 3.5301 - val_mean_absolute_error: 1.4751\n",
            "Epoch 27/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.6756 - mean_absolute_error: 1.2269 - val_loss: 1.8736 - val_mean_absolute_error: 0.6609\n",
            "Epoch 28/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5776 - mean_absolute_error: 1.1958 - val_loss: 3.4930 - val_mean_absolute_error: 1.4672\n",
            "Epoch 29/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5982 - mean_absolute_error: 1.1989 - val_loss: 2.4019 - val_mean_absolute_error: 0.9560\n",
            "Epoch 30/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.8361 - mean_absolute_error: 1.2651 - val_loss: 1.8407 - val_mean_absolute_error: 0.8002\n",
            "Epoch 31/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.7486 - mean_absolute_error: 1.2394 - val_loss: 2.5718 - val_mean_absolute_error: 1.1218\n",
            "Epoch 32/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.8388 - mean_absolute_error: 1.2597 - val_loss: 2.6550 - val_mean_absolute_error: 1.0933\n",
            "Epoch 33/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.7663 - mean_absolute_error: 1.2373 - val_loss: 2.6334 - val_mean_absolute_error: 1.0769\n",
            "Epoch 34/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5701 - mean_absolute_error: 1.1948 - val_loss: 2.3271 - val_mean_absolute_error: 0.8134\n",
            "Epoch 35/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.7513 - mean_absolute_error: 1.2307 - val_loss: 2.4666 - val_mean_absolute_error: 0.8303\n",
            "Epoch 36/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 3.4613 - mean_absolute_error: 1.4028 - val_loss: 2.4375 - val_mean_absolute_error: 1.0294\n",
            "Epoch 37/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 3.1477 - mean_absolute_error: 1.3308 - val_loss: 2.6462 - val_mean_absolute_error: 1.1682\n",
            "Epoch 38/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.9739 - mean_absolute_error: 1.2868 - val_loss: 1.7938 - val_mean_absolute_error: 0.6613\n",
            "Epoch 39/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5432 - mean_absolute_error: 1.1747 - val_loss: 3.4103 - val_mean_absolute_error: 1.3704\n",
            "Epoch 40/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.7083 - mean_absolute_error: 1.2254 - val_loss: 2.1974 - val_mean_absolute_error: 1.0176\n",
            "Epoch 41/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5615 - mean_absolute_error: 1.1882 - val_loss: 2.3275 - val_mean_absolute_error: 1.0241\n",
            "Epoch 42/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.7449 - mean_absolute_error: 1.2427 - val_loss: 1.9567 - val_mean_absolute_error: 0.7148\n",
            "Epoch 43/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.7125 - mean_absolute_error: 1.2241 - val_loss: 2.0609 - val_mean_absolute_error: 0.7383\n",
            "Epoch 44/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.7860 - mean_absolute_error: 1.2398 - val_loss: 2.0441 - val_mean_absolute_error: 0.6760\n",
            "Epoch 45/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5155 - mean_absolute_error: 1.1765 - val_loss: 1.8555 - val_mean_absolute_error: 0.6309\n",
            "Epoch 46/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.5294 - mean_absolute_error: 1.1797 - val_loss: 1.8542 - val_mean_absolute_error: 0.6180\n",
            "Epoch 47/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.9323 - mean_absolute_error: 1.2779 - val_loss: 2.5594 - val_mean_absolute_error: 1.1199\n",
            "Epoch 48/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.8310 - mean_absolute_error: 1.2468 - val_loss: 2.0875 - val_mean_absolute_error: 0.7242\n",
            "Epoch 49/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.6539 - mean_absolute_error: 1.2083 - val_loss: 1.7671 - val_mean_absolute_error: 0.6990\n",
            "Epoch 50/50\n",
            "5286/5286 [==============================] - 10s 2ms/step - loss: 2.6913 - mean_absolute_error: 1.2180 - val_loss: 2.4121 - val_mean_absolute_error: 0.9929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6e88e2c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdRBFopDRGOt",
        "colab_type": "text"
      },
      "source": [
        "Predicting for test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzNMc7H546di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/facial_keypoint/test.csv\")\n",
        "lookid_data=pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/facial_keypoint/IdLookupTable.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6R7_kVBRekt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "d86b9df2-bd1c-46c6-e16d-8c116a43d506"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>Image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>182 183 182 182 180 180 176 169 156 137 124 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>76 87 81 72 65 59 64 76 69 42 31 38 49 58 58 4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>177 176 174 170 169 169 168 166 166 166 161 14...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>176 174 174 175 174 174 176 176 175 171 165 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>50 47 44 101 144 149 120 58 48 42 35 35 37 39 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ImageId                                              Image\n",
              "0        1  182 183 182 182 180 180 176 169 156 137 124 10...\n",
              "1        2  76 87 81 72 65 59 64 76 69 42 31 38 49 58 58 4...\n",
              "2        3  177 176 174 170 169 169 168 166 166 166 161 14...\n",
              "3        4  176 174 174 175 174 174 176 176 175 171 165 15...\n",
              "4        5  50 47 44 101 144 149 120 58 48 42 35 35 37 39 ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezk7mJ6iRksI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c9d7bbf1-b70e-4812-cefa-064487ca9c8b"
      },
      "source": [
        "test.isnull().any().value_counts()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL-20-6A6I_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['Image']=test['Image'].apply(lambda x: np.fromstring(x, sep=' ') )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8iI1ReQ6QDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgdata=test['Image']\n",
        "test_img=np.vstack(imgdata.values)\n",
        "test_img=test_img.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBijYIwdVDn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test=test_img.reshape(-1,96,96,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRebjmzS6ksY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTj-j4Hx6nqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lookid_list = list(lookid_data['FeatureName'])\n",
        "imageID = list(lookid_data['ImageId']-1)\n",
        "pre_list = list(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwhKzQif6wuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rowid = lookid_data['RowId']\n",
        "rowid=list(rowid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul5PqI8I7Ve-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature = []\n",
        "for f in list(lookid_data['FeatureName']):\n",
        "    feature.append(lookid_list.index(f))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OHL1FJeZg45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preded = []\n",
        "for x,y in zip(imageID,feature):\n",
        "    preded.append(pre_list[x][y])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5A1m2L5ZjHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rowid = pd.Series(rowid,name = 'RowId')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXuHcGnUZlqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loc = pd.Series(preded,name = 'Location')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QRyfwBzZoO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.concat([rowid,loc],axis = 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymAf4rquZuSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('Submission.csv',index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}